{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8f5add",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-28T06:51:25.610353Z",
     "iopub.status.busy": "2025-06-28T06:51:25.610023Z",
     "iopub.status.idle": "2025-06-28T06:51:46.987037Z",
     "shell.execute_reply": "2025-06-28T06:51:46.985931Z"
    },
    "papermill": {
     "duration": 21.382303,
     "end_time": "2025-06-28T06:51:46.988735",
     "exception": false,
     "start_time": "2025-06-28T06:51:25.606432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 82960\n",
      "[LightGBM] [Info] Number of data points in the train set: 2767, number of used features: 3095\n",
      "[LightGBM] [Info] Start training from score -1.097890\n",
      "[LightGBM] [Info] Start training from score -1.098974\n",
      "[LightGBM] [Info] Start training from score -1.098974\n",
      "\n",
      "[Validation Classification Report on Oversampled Data]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        easy       0.89      0.93      0.91       102\n",
      "      medium       0.90      0.80      0.85       103\n",
      "        hard       0.88      0.94      0.91       103\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "\n",
      "[Accuracy on Original Train (No Oversampling)]: 0.8553259141494436\n",
      "[Classification Report on Original Train]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        easy       0.79      0.91      0.85       432\n",
      "      medium       0.93      0.81      0.87      1025\n",
      "        hard       0.78      0.90      0.84       430\n",
      "\n",
      "    accuracy                           0.86      1887\n",
      "   macro avg       0.84      0.88      0.85      1887\n",
      "weighted avg       0.87      0.86      0.86      1887\n",
      "\n",
      "\n",
      "[Test Prediction Distribution]\n",
      "difficulty\n",
      "medium    239\n",
      "easy      143\n",
      "hard       90\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[Sample Submission Preview]\n",
      "     id difficulty\n",
      "0  1013       easy\n",
      "1  1218     medium\n",
      "2  1716     medium\n",
      "3  1464       easy\n",
      "4  2227       hard\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def extract_code_features(df):\n",
    "    df['char_len'] = df['code'].str.len()\n",
    "    df['word_count'] = df['code'].apply(lambda x: len(x.split()))\n",
    "    df['sentence_count'] = df['code'].apply(lambda x: x.count('.') + x.count('\\n'))\n",
    "    df['avg_token_len'] = df['code'].apply(lambda x: np.mean([len(w) for w in x.split()]) if x.split() else 0)\n",
    "    df['num_digits'] = df['code'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "    df['num_loops'] = df['code'].str.count(r'\\bfor\\b|\\bwhile\\b')\n",
    "    df['num_if'] = df['code'].str.count(r'\\bif\\b')\n",
    "    df['num_functions'] = df['code'].str.count(r'\\bdef\\b|\\bfunction\\b|\\bvoid\\b')\n",
    "    df['num_comments'] = df['code'].str.count(r'#|//|/\\*|\\*/')\n",
    "    df['has_O_complexity'] = df['code'].str.contains(r'O\\([^)]+\\)', flags=re.IGNORECASE).astype(int)\n",
    "    df['contains_tree'] = df['code'].str.contains(r'\\btree\\b', flags=re.IGNORECASE).astype(int)\n",
    "    df['contains_dp'] = df['code'].str.contains(r'dynamic programming|\\bdp\\b', flags=re.IGNORECASE).astype(int)\n",
    "    df['contains_hash'] = df['code'].str.contains(r'\\bhash', flags=re.IGNORECASE).astype(int)\n",
    "    df['contains_stack'] = df['code'].str.contains(r'\\bstack\\b', flags=re.IGNORECASE).astype(int)\n",
    "    df['contains_recursive'] = df['code'].str.contains(r'\\brecursive|\\brecursion', flags=re.IGNORECASE).astype(int)\n",
    "    df['has_algo_steps'] = df['code'].str.contains(r'^\\s*\\d+\\.', flags=re.M).astype(int)\n",
    "    return df\n",
    "\n",
    "# === 1. Предобработка ===\n",
    "sample_submission = pd.read_csv('/kaggle/input/kz-tst-day-3/sample_submission.csv')\n",
    "train = pd.read_csv('/kaggle/input/kz-tst-day-3/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/kz-tst-day-3/test.csv')\n",
    "\n",
    "train['code'] = train['code'].fillna('').astype(str).str.strip()\n",
    "train = train[train['code'].str.len() > 0]\n",
    "train = train.dropna(subset=['difficulty'])\n",
    "train['difficulty'] = train['difficulty'].map({'easy': 0, 'medium': 1, 'hard': 2})\n",
    "\n",
    "# Сохраним копию train до oversampling для оценки\n",
    "train_orig = train.copy()\n",
    "\n",
    "# === 2. Балансировка классов через oversampling ===\n",
    "max_count = train['difficulty'].value_counts().max()\n",
    "train_bal = pd.concat([\n",
    "    train[train['difficulty'] == 0].sample(max_count, replace=True, random_state=42),\n",
    "    train[train['difficulty'] == 1].sample(max_count, replace=True, random_state=42),\n",
    "    train[train['difficulty'] == 2].sample(max_count, replace=True, random_state=42)\n",
    "])\n",
    "\n",
    "# === 3. Извлечение признаков ===\n",
    "train_bal = extract_code_features(train_bal)\n",
    "feature_cols = [\n",
    "    'char_len', 'word_count', 'sentence_count', 'avg_token_len', 'num_digits',\n",
    "    'num_loops', 'num_if', 'num_functions', 'num_comments',\n",
    "    'has_O_complexity', 'contains_tree', 'contains_dp',\n",
    "    'contains_hash', 'contains_stack', 'contains_recursive', 'has_algo_steps'\n",
    "]\n",
    "X_meta = train_bal[feature_cols].values\n",
    "\n",
    "# === 4. TF-IDF ===\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1, 2),\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\"\n",
    ")\n",
    "X_tfidf = tfidf.fit_transform(train_bal['code'])\n",
    "\n",
    "# === 5. Объединяем ===\n",
    "X_full = hstack([X_tfidf, csr_matrix(X_meta)])\n",
    "y = train_bal['difficulty']\n",
    "\n",
    "# === 6. Train / Validation + обучение ===\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_full, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "model = LGBMClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === 7. Оценка ===\n",
    "y_pred = model.predict(X_val)\n",
    "print('\\n[Validation Classification Report on Oversampled Data]')\n",
    "print(classification_report(y_val, y_pred, target_names=['easy', 'medium', 'hard']))\n",
    "\n",
    "# === 8. Оценка на оригинальном train (до oversampling) ===\n",
    "train_orig = extract_code_features(train_orig)\n",
    "X_orig_meta = train_orig[feature_cols].values\n",
    "X_orig_tfidf = tfidf.transform(train_orig['code'])\n",
    "X_orig_full = hstack([X_orig_tfidf, csr_matrix(X_orig_meta)])\n",
    "y_orig = train_orig['difficulty']\n",
    "y_orig_pred = model.predict(X_orig_full)\n",
    "\n",
    "print('\\n[Accuracy on Original Train (No Oversampling)]:', accuracy_score(y_orig, y_orig_pred))\n",
    "print('[Classification Report on Original Train]')\n",
    "print(classification_report(y_orig, y_orig_pred, target_names=['easy', 'medium', 'hard']))\n",
    "\n",
    "# === 9. Предсказание на test ===\n",
    "test['code'] = test['code'].fillna('').astype(str).str.strip()\n",
    "test = extract_code_features(test)\n",
    "X_test_meta = test[feature_cols].values\n",
    "X_test_tfidf = tfidf.transform(test['code'])\n",
    "X_test_full = hstack([X_test_tfidf, csr_matrix(X_test_meta)])\n",
    "test_preds = model.predict(X_test_full)\n",
    "\n",
    "# === 10. Сабмишен ===\n",
    "difficulty_map = {0: 'easy', 1: 'medium', 2: 'hard'}\n",
    "sample_submission['difficulty'] = pd.Series(test_preds).map(difficulty_map)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# === 11. Просмотр ===\n",
    "print('\\n[Test Prediction Distribution]')\n",
    "print(sample_submission['difficulty'].value_counts())\n",
    "print('\\n[Sample Submission Preview]')\n",
    "print(sample_submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12859381,
     "sourceId": 106291,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.180687,
   "end_time": "2025-06-28T06:51:48.012916",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-28T06:51:20.832229",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
